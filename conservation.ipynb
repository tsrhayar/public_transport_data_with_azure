{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd00173c-235d-403b-993f-e1b6b8e88eb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'public_transport_data_month_1' déjà traité.\n",
      "'public_transport_data_month_2' déjà traité.\n",
      "'public_transport_data_month_3' déjà traité.\n",
      "'public_transport_data_month_4' déjà traité.\n",
      "'public_transport_data_month_5' déjà traité.\n",
      "Tous les fichiers sont traité\n"
     ]
    }
   ],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %run \"./script import csv\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# CAlculate the duration on minutes\n",
    "def get_file_duration(path):\n",
    "    modification_time_ms = path.modificationTime\n",
    "    modification_time = datetime.fromtimestamp(modification_time_ms / 1000)  # Divide by 1000 to convert milliseconds to minute\n",
    "    duration = (datetime.now() - modification_time).total_seconds() / 60\n",
    "    return duration\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Archive files from the raw directory\n",
    "def archived_raw_files(raw_paths):\n",
    "    for path in raw_paths:\n",
    "        file_duration = get_file_duration(path)\n",
    "        # check if the duration \n",
    "        if file_duration >= 5:\n",
    "            # get the raw directory\n",
    "            source_directory = path.path\n",
    "            # get the archived directory\n",
    "            destination_directory = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/public_transport_data/archived/{path.name}\"\n",
    "            dbutils.fs.mv(source_directory, destination_directory,recurse = True)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Delete the archived files\n",
    "def delete_archived_files(archived_paths):\n",
    "    for path in archived_paths:\n",
    "        file_duration = get_file_duration(path)\n",
    "        # check if the duration \n",
    "        if file_duration >= 10:\n",
    "            # get the raw directory\n",
    "            source_directory = path.path\n",
    "            # get the archived directory\n",
    "            destination_directory = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/public_transport_data/archived/{path.name}\"\n",
    "            dbutils.fs.rm(destination_directory,recurse = True)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "storage_account_name = \"tahasrhstorageaccount\"\n",
    "storage_account_access_key = \"OCGL4AOQKWaFu6lezWKGDCVXDe7534tiifLMFUgdrPm6YJ3Vff3CMX5EGbxwIXGgBkdqnO6xomBP+ASti5On2w==\"\n",
    "container_name = \"tahasrhayarcontainer\"\n",
    "\n",
    "# get files path\n",
    "files_paths = get_file_path(storage_account_name,storage_account_access_key,container_name)\n",
    "\n",
    "# Execute function to apply the conservation policies\n",
    "archived_raw_files(files_paths[0])\n",
    "delete_archived_files(files_paths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7405b1d6-2d68-4e26-aa83-5f00cad9f402",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2023-09-27 14_29_53",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
